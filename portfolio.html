<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Wei Zhe Liu's Portfolio</title>
    <link rel="icon" href="/favicon.ico" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css"
    />
    <link rel="stylesheet" href="style.css" />
  </head>

  <body>
    <main>
      <div class="header">
        <h1 style="color: white;">Wei Zhe Liu</h1>
        <ul class="icons">
          <li>
            <a href="https://www.linkedin.com/in/wei-zhe-liu-34a2851b7/"
              ><i class="bi bi-linkedin"></i
            ></a>
          </li>
          <li>
            <a href="https://github.com/Oxcitzen"
              ><i class="bi bi-github"></i
            ></a>
          </li>
          <li>
            <a
              href="https://raw.githubusercontent.com/oxcitzen/oxcitzen.github.io/main/resume.pdf"
              ><h2>Resume</h2></a
            >
          </li>
        </ul>
      </div>
      <hr />
      <section>
        <h3>About Me</h3>
        <div class="row">
          <div class="column">
            <p>
              Greetings! I am a student at Purdue University majoring in Data Science. The dynamic world of data analysis and 
              machine learning captivates me, and I am eager to explore how I can apply my skills and knowledge to real-world projects. 
              My journey in data science has only just begun, and my goal is to harness the power of data to drive positive change. 
              I am excited to embark on new opportunities, collaborations, and projects that push the boundaries of data science and 
              make a difference in the world. Below are some of the projects I have worked on:
            </p>
            <br>
         
          </div>
        </div>
      </section>
      <section>
        <h3>Celebrity Image Classification</h3>
        <div class="content">
          <div class="row">
            <div class="column">
                <img src="images/daniel.png" style="width: 100%; max-width: 650px;" />
            </div>
        </div>
        <div class="row">
          <div class="column">
          
          <p>
            This project is a machine learning project focused on classifying images of five actors: Emily Blunt, John David Washington, 
            Michelle Yeoh, Saoirse Ronan, and Tony Leung. It covers various aspects of data science and machine learning, 
            including data collection, data cleaning, feature engineering, model building, model fine-tuning, and model deployment. 
          </p>
          <p>
            Data collection involved utilizing the Fatkun Chrome tool to download images of the celebrities from sources like Google Images and Bing Images.
            Fatkun is a powerful and user-friendly Google Chrome extension that simplifies the process of bulk image download from web pages.
            It provides an intuitive interface that allows users to easily select and save multiple images with just a few clicks. 
            The decision to use Fatkun for image collection is based on its ease of use and time efficiency. 
            This approach eliminates the need for coding and reduces the complexity of the data collection workflow.
          </p>

          <p>
            Data cleaning involved two tasks: face detection and image resizing. Face detection was performed using OpenCV to crop out the faces of the celebrities from the images. 
            Image resizing was done to standardize the cropped faces to a size of 32 x 32 pixels. 
            Feature engineering included wavelet transforms and color histograms. 
            Wavelet transforms were used to extract low-level features from grayscale face images using PyWavelets. 
            Color histograms were used to extract high-level features from color face images using OpenCV.
          </p>

          <p>
            Model building consisted of building three models: SVM, logistic regression, and random forest. 
            These models were trained on the extracted features and the labels of the celebrities. 
            Model fine-tuning involved optimizing the hyperparameters of the models using cross-validation and grid search. 
            Cross-validation evaluated the model performance using accuracy as a metric, and grid search searched for the best hyperparameter 
            combinations.
          </p>
          <p>
            The project resulted in trained models for each actor. These models can be used for classifying new images of the actor. 
            Overall, the project showcases the complete pipeline of a data science and machine learning project, 
            from data collection and cleaning to feature engineering, model building, and fine-tuning.
          </p>

          
          <p>
            The code for this project can be found on
            <a href="https://github.com/Oxcitzen/Celebrity-Image-Classfication-Model"
              >GitHub</a
            >
          </p> 
        </div>
      </div>
          <div class="column project">
            <br>
            <h3>Forecasting Household Electric Power Consumption With Time Series Data</h3>
            <div class="content">
              <div class="row">
                <div class="column">
                    <img src="images/electric.png" style="width: 100%; max-width: 650px;" />
                </div>
            </div>
            <div class="row">
              <div class="column">
              
              <p>
                During this project, I extensively analyzed the 
                <a href="http://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption"
                >household electric power consumption dataset</a> 
                from the UCI Machine Learning Repository. My exploratory data analysis involved various insightful steps, including plotting 
                the distribution and time series of the global active power, decomposing the time series into trend, seasonality, and residual components, 
                testing the stationarity of the time series, and visualizing the autocorrelation and partial autocorrelation functions. Through these analyses, 
                I made intriguing discoveries, identifying a noticeable downward trend, yearly seasonality, and some weekly 
                periodicity within the time series. 
              </p>

              <p>
                
              Continuing with my research, I leveraged the power of a LSTM (Long Short-Term Memory) network to forecast the global active 
              power. To prepare the data for modeling, I applied MinMaxScaler for scaling and reshaped it into a three-dimensional array. 
              I designed the LSTM network, comprising one hidden layer with 50 neurons and one output layer. 
              Employing mean squared error as the loss function and the Adam optimizer, I trained the model for 100 epochs using a batch 
              size of 70.
              </p>

              <p>
                However, during the training process, I implemented early stopping to prevent overfitting. 
                The model effectively stopped at epoch 22, which ensured that I obtained an optimal performance without sacrificing generalization.
                The LSTM model exhibited a training loss of 0.01 and validation loss of 0.094, signifying its effectiveness in making accurate 
                predictions. The visually appealing plots of predicted values alongside the actual values validated the model's reliability and 
                showcased its potential for practical applications.
              </p>
 
              <p>
                The code for this project can be found on
                <a href="https://github.com/Oxcitzen/Household-Electric-Consumption-Over-Time-Analysis"
                  >GitHub</a
                >
              </p> 
            </div>
          </div>
          <div class="column project">
            <br>
            <h3>Dream Housing Loan Prediction</h3>
            <div class="column project">
              <img src="images/binary.png" style="width: 100%; max-width: 650px;" />
              <p>
                To tackle the loan eligibility prediction problem for  <a
                href="https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/#ProblemStatement"
                >Dream Housing Finance company</a
              >,
                I embarked on a comprehensive data analysis journey. Through exploratory data analysis, 
                I gained insights into the variables and their distributions, visualizing the relationships 
                between features and loan approval status. I encountered a noticeable class imbalance, 
                with a significant difference between approved and rejected loans.
              </p>
              <p>
                Handling missing values was crucial, and I applied appropriate imputation methods based on variable distributions. 
                Skewed numerical variables underwent log transformations, aligning them with a normal distribution and improving 
                the performance of machine learning algorithms. Dealing with outliers involved visualizing and removing them using 
                box whisker plots and the interquartile range. This step ensured that the model focused on underlying patterns 
                rather than being influenced by extreme values.
              </p>
              <p>
                Categorical variables were transformed into numerical representations using one-hot encoding, expanding them into binary columns. 
                This prepared the dataset for modeling with powerful machine learning algorithms. To address class imbalance, 
                I employed the Synthetic Minority Over-sampling Technique (SMOTE), generating synthetic samples of the minority class. 
                This balanced the class distribution and improved the model's ability to learn from representative data.
              </p>
              <p>
                Using eleven popular classifiers, I compared their performance and identified the top performers based on accuracy.Decision Tree, 
                Random Forest, Extra Trees, Gradient Boosting, and Multiple Layer Perceptron emerged as the most accurate classifiers. 
                To further boost accuracy and robustness, I implemented an ensemble modeling approach using the Voting Classifier. 
                This technique combined the predictions of selected models, resulting in a 77.8% accuracy for loan eligibility prediction. 
                The Voting Classifier harnessed the collective power of multiple models, elevating the overall performance of the system.
                
              </p>

              
              <p>
                The code for this project can be found on
                <a href="https://github.com/Oxcitzen/Dream-Housing-Loan-Prediction/tree/main"
                  >GitHub</a
                >
              </p>
            </div>
          </div>
          
          <div class="column project">
            <br>
            <h3>Lightning Wilfire Lab</h3>
            <div class="content">
                <div class="row">
                    <div class="column">
                        <img src="images/wildfire.png" style="width: 100%; max-width: 800px;" />
                    </div>
                </div>
                <div class="row">
                    <div class="column">
              
              <p>
                I am currently working on a lightning wildfire research project led by Professor Yuan Wang at my university. 
                The primary objective of the research is to implement statistical models to find the correlation between lightning and fires, 
                and build machine learning models to predict the locations of fires based on lightning strikes. In this past semester, 
                our team has been focused on setting up Python scripts to automate the extraction of satellite data (GOES-R) 
                and perform data visualization and cleaning for machine learning use.
              </p>
              <p>
                Throughout the project, I assumed the responsibility of supervising code development and organizing the research workflow 
                within the lab. This involved handling the evaluation and integration of new scripts to create an efficient system that 
                facilitated information querying and visualization for other researchers. Furthermore, I automated API requests to collect 
                extensive fire data from USGS (United States Geological Survey). The ultimate goal of this endeavor was to leverage deep 
                learning models to uncover the correlation between lightning strikes and wildfires. <br>
              </p>
            
            </div>
          </div>
        </div>
          <div class="column project">
            <br>
            <h3>Business Sales Insights with Power BI</h3>
            <div class="content">
              <div class="row">
                <div class="column">
                  <img src="images/bi.png" style="width: 100%; max-width: 700px;" />
                </div>
              </div>
              <div class="row">
                <div class="column">
            <p>
              In my data analysis project using Power BI, I harnessed the power of data to drive business success. 
              By extracting insights from diverse data sources such as sales transactions, customer demographics, and market trends, 
              I aimed to empower businesses with actionable sales insights. Power BI's connectivity capabilities allowed me to seamlessly 
              connect to these data sources, ensuring a comprehensive view of the business landscape. 
              With a solid data modeling foundation and the use of Data Analysis Expressions (DAX), 
              I gained a deeper understanding of the data and generated custom calculations such as sales growth and customer lifetime value.
            </p>
            <p>
              To provide real-time insights, I designed interactive dashboards using Power BI. These visually engaging dashboards served as 
              a dynamic window into the latest sales trends and market insights. By incorporating interactive visualizations like charts, 
              graphs, and maps, I enabled stakeholders to explore data, identify patterns, and make data-driven decisions. 
              These dashboards became powerful tools for monitoring sales performance, detecting market trends, and uncovering growth opportunities.
            </p>
            <p>
              Through my project using Power BI, I transformed raw data into actionable insights. By connecting to various data sources, building robust data models, 
              and applying custom calculations, I unveiled hidden stories within the data. The interactive dashboards 
              I created not only provided real-time sales insights but also empowered businesses to identify market trends and make informed decisions.
            </p>
            <p>
              The code for this project can be found on
              <a
                href="https://github.com/Oxcitzen/Business-Sales-Insights-Power-BI"
                >GitHub</a
              >.
            </p>
          </div>
        </div>
      </section>
      <section>
        
        <footer>
          <div class="column">Made by Wei Zhe Liu
          <div class="column">
            <br>
            <div>
              Website Code on
              <a href="https://github.com/Oxcitzen/wz.me.github.io"
                >GitHub</a
              >
            </div>
          </div>
        </footer>
        
      </section>
    </main>
 
  </body>
</html>
